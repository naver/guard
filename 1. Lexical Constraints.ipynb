{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82ed43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from disco.scorers import BooleanScorer\n",
    "from disco.distributions import LMDistribution\n",
    "from disco.samplers import AccumulationSampler\n",
    "from disco.tuners import DPGTuner\n",
    "from disco.tuners.loggers.console import ConsoleLogger\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fa7f5",
   "metadata": {},
   "source": [
    "# Basic interface and experiments with CAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d733e6f",
   "metadata": {},
   "source": [
    "Define Base LLM a(y) and binary constraint b(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab04985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "a = LMDistribution(\"google/gemma-2b\", token=token, LLM=True) # base LLM a(y)\n",
    "b = lambda s, c: bool(re.search(r\"\\bamazing\\b\", s.text)) # hard constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b84d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = AccumulationSampler(distribution=a, total_size=200000) # Total sample size what you want\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=\"\") # If GPU-extensive, than lower sampling size.\n",
    "print('AR =', sum([b(s, _) for s in samples_a]) / len(samples_a)) # AR_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e7440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CAP (context-aware prompt) what you want\n",
    "\n",
    "CAP = \"Next sentence should contain 'amazing'.\\n\\n\"\n",
    "\n",
    "# CAP = \"Write sentences with the given words.\\n\"\n",
    "# CAP += \"diagnosis: Assessment of microscopical and clinical parameters in the diagnosis of diabetes mellitus.\\n\"\n",
    "# CAP += \"pandas: Column headings differ in spreadsheet that is merged with pandas data\\n\"\n",
    "# CAP += \"change: How to change the decimal separator in MS Word?\\n\"\n",
    "# CAP += \"amazing: \"\n",
    "# CAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f943333",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = AccumulationSampler(distribution=a, total_size=50000) \n",
    "samples_a2, distr_a2 = distr.sample(sampling_size=250, context=CAP) # sample with CAP\n",
    "print('AR =', sum([b(s, _) for s in samples_a2]) / len(samples_a2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53daa2",
   "metadata": {},
   "source": [
    "$$Z = AR_a = \\mathbb{E}_{y \\sim a} b(y), Z2 = AR_{a2} = \\mathbb{E}_{y \\sim a2} b(y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc388ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sum([b(s, _) for s in samples_a]) / len(samples_a)\n",
    "Z2 = sum([b(s, _) for s in samples_a2]) / len(samples_a2)\n",
    "print('Z and log(Z):', Z, sp.log(Z))\n",
    "print(\"Z' and log(Z'):\", Z2, sp.log(Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f038f9f7",
   "metadata": {},
   "source": [
    "$$KL(g|a) = \\mathbb{E}_{y\\sim g} \\log \\frac{g(y)}{a(y)} = \\mathbb{E}_{y\\sim g} \\log \\frac{a(y) b(y)}{Z\\ a(y)}= \\mathbb{E}_{y\\sim g} \\log \\frac{1}{Z} = -\\log Z$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87170fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "-sp.log(Z), -sp.log(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aee22",
   "metadata": {},
   "source": [
    "Estimator: $$\\mathbb{E}_{y \\sim g} \\log \\frac{a(y)}{a'(y)} \\ and \\ \\mathbb{E}_{y\\sim g2} \\log \\frac{a(y)}{a'(y)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfda0bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for it, item in enumerate(samples_a):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a[it]], context=\"\") - a.log_score([samples_a[it]], context=gop))\n",
    "        \n",
    "estimator_g = sum(score)/len(score)\n",
    "\n",
    "score = []\n",
    "for it, item in enumerate(samples_a2[:10000]):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a2[it]], context=\"\") - a.log_score([samples_a2[it]], context=gop))\n",
    "\n",
    "estimator_g2 = sum(score)/len(score)\n",
    "\n",
    "estimator_g, estimator_g2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b635bc",
   "metadata": {},
   "source": [
    "$$KL(g|a’) = \\mathbb{E}_{y\\sim g} \\log \\frac{g(y)}{a'(y)} = \\mathbb{E}_{y\\sim g} \\log \\frac{a(y) b(y)}{Z\\ a'(y)} = \\mathbb{E}_{y\\sim g} \\log \\frac{a(y)}{a'(y)} -\\log Z$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2ac22",
   "metadata": {},
   "source": [
    "$$KL(g|g’) = \\mathbb{E}_{y\\sim g} \\log \\frac{g(y)}{g'(y)} = \\mathbb{E}_{y\\sim g} \\log \\frac{a(y) b(y)}{Z}\\frac{Z'}{a'(y)b(y)} = \\mathbb{E}_{y\\sim g} \\log \\frac{a(y)}{a'(y)}-\\log \\frac{Z}{Z'}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_g-sp.log(Z), estimator_g-sp.log(Z)+sp.log(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f338578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AR upgrade: \", Z2/Z)\n",
    "print(\"KL(g|g')\", estimator_g-sp.log(Z)+sp.log(Z2))\n",
    "print(\"KL(g'|g)\", -estimator_g2-sp.log(Z2)+sp.log(Z))\n",
    "print(\"AR of a2: \", Z2)\n",
    "print(\"KL(g|a):\", -sp.log(Z))\n",
    "print(\"KL(g'|a'):\", -sp.log(Z2))\n",
    "print(\"KL(g|a')\", estimator_g-sp.log(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f40b8",
   "metadata": {},
   "source": [
    "# DPG Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f0517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "proposal = LMDistribution(\"google/gemma-2b\", token=token, LLM=True)\n",
    "a2 = LMDistribution(\"google/gemma-2b\", token=token, LLM=True, freeze=False)\n",
    "b = lambda s, c: bool(re.search(r\"\\bamazing\\b\", s.text)) # hard constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd660306",
   "metadata": {},
   "source": [
    "Define our gold distribution $g(y)$ !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BooleanScorer(b)\n",
    "g = proposal * scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c94196",
   "metadata": {},
   "source": [
    "DPG Training with $disco$ libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = DPGTuner(a2, g,\n",
    "        context=\"\",\n",
    "        n_gradient_steps=400,\n",
    "        n_samples_per_step=10000,\n",
    "        sampling_size=500,\n",
    "        scoring_size=500,\n",
    "        divergence_evaluation_interval=10)\n",
    "\n",
    "ConsoleLogger(tuner)\n",
    "\n",
    "tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.save(path=\"models/amazing/dpg-800k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9d3ad6",
   "metadata": {},
   "source": [
    "Evaluate as above protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb29a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "a = LMDistribution(\"google/gemma-2b\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a, total_size=500000)\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a]) / len(samples_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a912d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = LMDistribution(\"models/amazing/dpg-800k\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a2, total_size=200000)\n",
    "samples_a2, distr_a2 = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a2]) / len(samples_a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sum([b(s, _) for s in samples_a]) / len(samples_a)\n",
    "Z2 = sum([b(s, _) for s in samples_a2]) / len(samples_a2)\n",
    "print('Z and log(Z):', Z, sp.log(Z))\n",
    "print(\"Z' and log(Z'):\", Z2, sp.log(Z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1392ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for it, item in enumerate(samples_a):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a[it]], context=\"\") - a2.log_score([samples_a[it]], context=\"\"))\n",
    "        \n",
    "estimator_g = sum(score)/len(score)\n",
    "\n",
    "score = []\n",
    "for it, item in enumerate(samples_a2[:10000]):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a2[it]], context=\"\") - a2.log_score([samples_a2[it]], context=\"\"))\n",
    "\n",
    "estimator_g2 = sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AR upgrade: \", Z2/Z)\n",
    "print(\"KL(g|g')\", estimator_g-sp.log(Z)+sp.log(Z2))\n",
    "print(\"KL(g'|g)\", -estimator_g2-sp.log(Z2)+sp.log(Z))\n",
    "print(\"AR of a2: \", Z2)\n",
    "print(\"KL(g|a):\", -sp.log(Z))\n",
    "print(\"KL(g'|a'):\", -sp.log(Z2))\n",
    "print(\"KL(g|a')\", estimator_g-sp.log(Z))\n",
    "print(\"KL(g'|a)\", -estimator_g2-sp.log(Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac78a480",
   "metadata": {},
   "source": [
    "# SFT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "model_name = \"google/gemma-2b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LMDistribution(model_name, token=token, LLM=True)\n",
    "b = lambda s, c: bool(re.search(r\"\\bamazing\\b\", s.text)) # hard constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5904b",
   "metadata": {},
   "source": [
    "sample a lot of $y$ from $a(y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = AccumulationSampler(distribution=a, total_size=800000)\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a8910",
   "metadata": {},
   "source": [
    "filter $y$ with $b(y)$ to make dataset representing $g$ distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_g = []\n",
    "\n",
    "for it, item in enumerate(samples_a): # y ~ a\n",
    "    if b(item, _): # if b(y) = 1\n",
    "        samples_g.append({'text': item[1]}) # return y\n",
    "\n",
    "print(len(samples_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6704a4d",
   "metadata": {},
   "source": [
    "Supervised fine-tuning with a dataset representing $g$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d607989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='models/sft',\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-06,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "ds_train = Dataset.from_list(samples_g) \n",
    "ds_train = ds_train.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07606250",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "a = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', trust_remote_code=True)\n",
    "# a.to('cuda')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=a,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    max_seq_length=30,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field='text',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"models/amazing/sft-800k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fca1f5",
   "metadata": {},
   "source": [
    "Evaluate as above protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "a = LMDistribution(\"google/gemma-2b\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a, total_size=500000)\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a]) / len(samples_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = LMDistribution(\"models/amazing/dpg-800k\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a2, total_size=200000)\n",
    "samples_a2, distr_a2 = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a2]) / len(samples_a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31103111",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sum([b(s, _) for s in samples_a]) / len(samples_a)\n",
    "Z2 = sum([b(s, _) for s in samples_a2]) / len(samples_a2)\n",
    "print('Z and log(Z):', Z, sp.log(Z))\n",
    "print(\"Z' and log(Z'):\", Z2, sp.log(Z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1549b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for it, item in enumerate(samples_a):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a[it]], context=\"\") - a2.log_score([samples_a[it]], context=\"\"))\n",
    "        \n",
    "estimator_g = sum(score)/len(score)\n",
    "\n",
    "score = []\n",
    "for it, item in enumerate(samples_a2[:10000]):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a2[it]], context=\"\") - a2.log_score([samples_a2[it]], context=\"\"))\n",
    "\n",
    "estimator_g2 = sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a64e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AR upgrade: \", Z2/Z)\n",
    "print(\"KL(g|g')\", estimator_g-sp.log(Z)+sp.log(Z2))\n",
    "print(\"KL(g'|g)\", -estimator_g2-sp.log(Z2)+sp.log(Z))\n",
    "print(\"AR of a2: \", Z2)\n",
    "print(\"KL(g|a):\", -sp.log(Z))\n",
    "print(\"KL(g'|a'):\", -sp.log(Z2))\n",
    "print(\"KL(g|a')\", estimator_g-sp.log(Z))\n",
    "print(\"KL(g'|a)\", -estimator_g2-sp.log(Z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7816c04",
   "metadata": {},
   "source": [
    "# Warm-start DPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "model_name = \"google/gemma-2b\"\n",
    "a = LMDistribution(model_name, token=token, LLM=True)\n",
    "b = lambda s, c: bool(re.search(r\"\\bamazing\\b\", s.text)) # hard constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dccdf9",
   "metadata": {},
   "source": [
    "Use CAP to make a lot of $y \\sim a(\\cdot|CAP)$ with small sampling budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94161c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAP = \"Next sentence should contain 'amazing'.\\n\\n\"\n",
    "distr = AccumulationSampler(distribution=a, total_size=10000)\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=CAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff30908",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_g = []\n",
    "\n",
    "for it, item in enumerate(samples_a): # y ~ a\n",
    "    if b(item, _): # if b(y) = 1\n",
    "        samples_g.append({'text': item[1]}) # return y\n",
    "\n",
    "print(len(samples_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b64b3d",
   "metadata": {},
   "source": [
    "fine-tune $y$ to make warm-start model.\n",
    "Note: Do not make too many gradient signal!! It is biased dataset!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfb1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='models/sft',\n",
    "    per_device_train_batch_size=24,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-06,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "ds_train = Dataset.from_list(samples_g) \n",
    "ds_train = ds_train.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdb9674",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "a = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto', trust_remote_code=True)\n",
    "# a.to('cuda')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=a,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    max_seq_length=30,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field='text',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"models/amazing/ws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c77be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "proposal = LMDistribution(\"google/gemma-2b\", token=token, LLM=True)\n",
    "a2 = LMDistribution(\"models/amazing/ws\", token=token, LLM=True, freeze=False)\n",
    "b = lambda s, c: bool(re.search(r\"\\bamazing\\b\", s.text)) # hard constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = BooleanScorer(b)\n",
    "g = proposal * scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = DPGTuner(a2, g,\n",
    "        context=\"\",\n",
    "        n_gradient_steps=799,\n",
    "        n_samples_per_step=10000,\n",
    "        sampling_size=500,\n",
    "        scoring_size=500,\n",
    "        divergence_evaluation_interval=10)\n",
    "\n",
    "ConsoleLogger(tuner)\n",
    "\n",
    "tuner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.save(path=\"models/amazing/wsdpg-800k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567c431",
   "metadata": {},
   "source": [
    "Evaluate with above protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"\" # your own huggingface token\n",
    "a = LMDistribution(\"google/gemma-2b\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a, total_size=500000)\n",
    "samples_a, distr_a = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a]) / len(samples_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10916abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = LMDistribution(\"models/amazing/wsdpg-800k\", token=token, LLM=True)\n",
    "\n",
    "distr = AccumulationSampler(distribution=a2, total_size=200000)\n",
    "samples_a2, distr_a2 = distr.sample(sampling_size=500, context=\"\")\n",
    "print('AR =', sum([b(s, _) for s in samples_a2]) / len(samples_a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sum([b(s, _) for s in samples_a]) / len(samples_a)\n",
    "Z2 = sum([b(s, _) for s in samples_a2]) / len(samples_a2)\n",
    "print('Z and log(Z):', Z, sp.log(Z))\n",
    "print(\"Z' and log(Z'):\", Z2, sp.log(Z2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for it, item in enumerate(samples_a):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a[it]], context=\"\") - a2.log_score([samples_a[it]], context=\"\"))\n",
    "        \n",
    "estimator_g = sum(score)/len(score)\n",
    "\n",
    "score = []\n",
    "for it, item in enumerate(samples_a2[:10000]):\n",
    "    if b(item, _):\n",
    "        score.append(a.log_score([samples_a2[it]], context=\"\") - a2.log_score([samples_a2[it]], context=\"\"))\n",
    "\n",
    "estimator_g2 = sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1011366",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AR upgrade: \", Z2/Z)\n",
    "print(\"KL(g|g')\", estimator_g-sp.log(Z)+sp.log(Z2))\n",
    "print(\"KL(g'|g)\", -estimator_g2-sp.log(Z2)+sp.log(Z))\n",
    "print(\"AR of a2: \", Z2)\n",
    "print(\"KL(g|a):\", -sp.log(Z))\n",
    "print(\"KL(g'|a'):\", -sp.log(Z2))\n",
    "print(\"KL(g|a')\", estimator_g-sp.log(Z))\n",
    "print(\"KL(g'|a)\", -estimator_g2-sp.log(Z2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guage",
   "language": "python",
   "name": "guage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
